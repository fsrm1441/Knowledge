# LangChain + DeepSeek 知识库示例
# 导入必要的库
import os
from dotenv import load_dotenv
# 移除无效的导入语句
# from huggingface_hub import set_proxy  # 修改导入
import requests.adapters
from langchain_deepseek import ChatDeepSeek
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
# 添加Word文档加载器
try:
    from langchain_community.document_loaders import Docx2txtLoader
except ImportError:
    print("警告: 未安装docx2txt库，将无法加载Word文档")
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA
# 在文件顶部添加必要的导入
from langchain import PromptTemplate

# 从.env文件加载环境变量
load_dotenv()

# 全局设置Hugging Face镜像源 - 使用清华大学镜像源
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'  # 设置环境变量

# 简化的配置方式，只需设置环境变量即可
# 不需要复杂的HTTP后端配置，环境变量设置是最简单可靠的方法

class DeepSeekKnowledgeBase:
    """基于DeepSeek和LangChain的知识库类"""
    def __init__(self):
        # 初始化DeepSeek模型
        self.llm = ChatDeepSeek(model="deepseek-chat", temperature=0.7)
        
        # 初始化嵌入模型 (使用开源的HuggingFace嵌入模型)
        # 通过清华镜像源下载模型
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            # 重要：首次下载时不要使用local_files_only，这样才能从镜像源下载
            # model_kwargs={'local_files_only': True}  # 下载完成后可以取消注释这行
        )
        
        # 知识库向量存储
        self.vector_store = None
        
        # 检索问答链
        self.qa_chain = None
    
    def create_knowledge_base(self, file_paths):
        """创建知识库
        Args:
            file_paths: 文档文件路径列表
        """
        documents = []
        
        # 加载每个文档
        for file_path in file_paths:
            if os.path.exists(file_path):
                # 根据文件扩展名选择不同的加载器
                if file_path.endswith('.txt'):
                    loader = TextLoader(file_path, encoding="utf-8")
                elif file_path.endswith('.docx'):
                    try:
                        loader = Docx2txtLoader(file_path)
                    except Exception as e:
                        print(f"加载Word文档 {file_path} 出错: {str(e)}")
                        continue
                else:
                    print(f"警告: 不支持的文件格式: {file_path}")
                    continue
                
                try:
                    document = loader.load()
                    documents.extend(document)
                except Exception as e:
                    print(f"加载文档 {file_path} 出错: {str(e)}")
            else:
                print(f"警告: 文件 {file_path} 不存在")
        
        if not documents:
            print("错误: 没有找到任何文档，请检查文件路径")
            return False
        
        # 分割文档
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(documents)
        
        # 创建向量存储
        self.vector_store = FAISS.from_documents(texts, self.embeddings)
        
        # 创建自定义提示词模板
        template = """
<instruction>

你是一个RAG专家，专注于回答名词解释。请按照以下步骤完成任务：
1. 使用提供的名词 {question} 生成准确、简洁的名词解释。
2. 解释应包含该名词的基本定义、常见用途或相关背景（如适用）。
3. 确保输出为纯文本，不包含任何XML标签或格式符号。
4. 若名词无法识别或解释，请明确回复“无法提供该名词的解释”。
</instruction>

<input>
需要解释的名词：{question}
</input>

上下文信息:
{context}
"""
        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        # 创建检索问答链并使用自定义提示词
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_store.as_retriever(search_kwargs={"k": 5}),
            return_source_documents=True,
            chain_type_kwargs={"prompt": prompt}
        )
        
        print(f"成功创建知识库，共加载 {len(documents)} 个文档，分割为 {len(texts)} 个片段")
        return True
    
    def query_knowledge_base(self, question):
        """查询知识库
        Args:
            question: 查询问题
        Returns:
            回答和相关文档
        """
        if not self.qa_chain:
            print("错误: 知识库尚未创建，请先调用create_knowledge_base方法")
            return None
        
        try:
            # 修改为与模板一致的变量名
            result = self.qa_chain.invoke({
                "query": question
            })
            
            # 格式化回答
            answer = result["result"]
            source_documents = result["source_documents"]
            
            return {
                "answer": answer,
                "sources": [
                    {
                        "content": doc.page_content,
                        "metadata": doc.metadata
                    } for doc in source_documents
                ]
            }
        except Exception as e:
            print(f"查询出错: {str(e)}")
            return None
    
    def save_knowledge_base(self, file_path):
        """保存知识库
        Args:
            file_path: 保存路径
        """
        if not self.vector_store:
            print("错误: 没有知识库可保存")
            return False
        
        try:
            # 提取目录路径
            dir_path = os.path.dirname(file_path)
            if dir_path and not os.path.exists(dir_path):
                os.makedirs(dir_path)
            
            # 保存向量存储
            self.vector_store.save_local(file_path)
            print(f"知识库已保存到 {file_path}")
            return True
        except Exception as e:
            print(f"保存知识库出错: {str(e)}")
            return False
    
    def load_knowledge_base(self, file_path):
        """加载已保存的知识库
        Args:
            file_path: 知识库文件路径
        """
        try:
            # 加载向量存储
            self.vector_store = FAISS.load_local(file_path, self.embeddings, allow_dangerous_deserialization=True)
            
            # 创建自定义提示词模板 - 与create_knowledge_base方法保持一致
            template = """
<instruction>

你是一个RAG专家，专注于回答名词解释。请按照以下步骤完成任务：
1. 使用提供的名词 {question} 生成准确、简洁的名词解释。
2. 解释应包含该名词的基本定义、常见用途或相关背景（如适用）。
3. 确保输出为纯文本，不包含任何XML标签或格式符号。
4. 若名词无法识别或解释，请明确回复“无法提供该名词的解释”。
</instruction>

<input>
需要解释的名词：{question}
</input>

上下文信息:
{context}
"""
            prompt = PromptTemplate(
                template=template,
                input_variables=["context", "question"]
            )
            
            # 创建检索问答链并使用自定义提示词
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                # 保持与上面相同的k值调整
                retriever=self.vector_store.as_retriever(search_kwargs={"k": 5}),
                return_source_documents=True,
                chain_type_kwargs={"prompt": prompt}  # 添加这一行以使用自定义提示词
            )
            
            print(f"成功加载知识库: {file_path}")
            return True
        except Exception as e:
            print(f"加载知识库出错: {str(e)}")
            return False


# 示例用法
if __name__ == "__main__":
    # 创建示例文档目录
    sample_docs_dir = "sample_docs"
    os.makedirs(sample_docs_dir, exist_ok=True)
    
    # 创建示例文档
    sample_content = """LangChain是一个用于构建大语言模型应用程序的框架。
它提供了一套工具、组件和接口，使开发者能够更容易地构建端到端的应用程序。

LangChain的主要特性包括：
1. 模型集成：支持多种大语言模型，如OpenAI、DeepSeek等
2. 检索增强：允许模型访问外部知识库
3. 代理系统：支持构建基于LLM的代理
4. 链式调用：简化复杂工作流的构建

LangChain的核心组件包括：
- 模型：各种LLM和聊天模型
- 提示：提示模板和管理
- 链：将多个组件链接在一起
- 文档加载器：加载各种格式的文档
- 向量存储：存储和检索嵌入向量
- 代理：使用LLM做出决策的代理系统
"""
    
    # 写入示例文档
    sample_doc_path = os.path.join(sample_docs_dir, "langchain_intro.txt")
    with open(sample_doc_path, "w", encoding="utf-8") as f:
        f.write(sample_content)
    
    print(f"已创建示例文档: {sample_doc_path}")
    
    # 初始化知识库
    kb = DeepSeekKnowledgeBase()
    
    # 创建知识库
    print("正在创建知识库...")
    kb.create_knowledge_base([sample_doc_path])
    
    # 保存知识库
    kb.save_knowledge_base("faiss_knowledge_base")
    
    # 交互式查询
    print("\n===== 知识库问答系统 =====")
    print("输入'退出'结束程序")
    
    while True:
        question = input("\n请输入您的问题: ")
        if question.lower() in ["退出", "exit", "quit"]:
            break
        
        result = kb.query_knowledge_base(question)
        if result:
            print(f"\n回答: {result['answer']}")
            
            # 显示相关来源
            print("\n相关来源:")
            for i, source in enumerate(result['sources'], 1):
                print(f"{i}. {source['metadata'].get('source', '未知来源')}")
                # 显示部分内容
                content_preview = source['content'][:100] + ("..." if len(source['content']) > 100 else "")
                print(f"   内容摘要: {content_preview}")

    print("程序已退出")